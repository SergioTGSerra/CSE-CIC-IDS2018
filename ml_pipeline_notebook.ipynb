{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0252e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Machine Learning Pipeline for Network Intrusion Detection\n",
    "# \n",
    "# This notebook implements a comprehensive machine learning pipeline for network intrusion detection using the CSE-CIC-IDS2018 dataset. The pipeline includes data preprocessing, exploratory data analysis, feature engineering, and various machine learning models for classification.\n",
    "# \n",
    "# ## Table of Contents\n",
    "# 1. [Setup and Imports](#setup)\n",
    "# 2. [Data Loading and Preprocessing](#preprocessing)\n",
    "# 3. [Exploratory Data Analysis (EDA)](#eda)\n",
    "# 4. [Feature Engineering](#feature_engineering)\n",
    "# 5. [Machine Learning Models](#ml_models)\n",
    "# 6. [Model Evaluation](#evaluation)\n",
    "# 7. [Model Deployment](#deployment)\n",
    "\n",
    "# <a id=\"setup\"></a>\n",
    "# ## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Basic data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import (\n",
    "    IsolationForest, RandomForestClassifier, GradientBoostingClassifier, \n",
    "    AdaBoostClassifier, VotingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report, roc_curve, auc, \n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# Neural Networks (optional)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    # Set random seed for TensorFlow\n",
    "    tf.random.set_seed(RANDOM_STATE)\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. Neural network models will be skipped.\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Set NumPy random seed\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Setup complete. All necessary libraries imported.\")\n",
    "\n",
    "# <a id=\"preprocessing\"></a>\n",
    "# ## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728a785",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(file_path=None, sample_size=None, create_sample=False, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file or create a sample dataset.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str, optional): Path to the CSV file\n",
    "        sample_size (int, optional): Number of rows to sample from the CSV file\n",
    "        create_sample (bool): Whether to create a synthetic sample dataset\n",
    "        n_samples (int): Number of samples to generate if create_sample is True\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded or created DataFrame\n",
    "    \"\"\"\n",
    "    if create_sample:\n",
    "        print(\"Creating sample dataset for demonstration...\")\n",
    "        return create_sample_dataset(n_samples)\n",
    "    \n",
    "    if file_path is None:\n",
    "        # Try to find CSV files in the data directory\n",
    "        data_dir = os.path.join(os.getcwd(), 'data')\n",
    "        if os.path.exists(data_dir):\n",
    "            csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "            if csv_files:\n",
    "                file_path = os.path.join(data_dir, csv_files[0])\n",
    "                print(f\"Found CSV file: {file_path}\")\n",
    "            else:\n",
    "                print(\"No CSV files found in the data directory. Creating sample dataset...\")\n",
    "                return create_sample_dataset(n_samples)\n",
    "        else:\n",
    "            print(\"Data directory not found. Creating sample dataset...\")\n",
    "            return create_sample_dataset(n_samples)\n",
    "    \n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File {file_path} not found. Creating sample dataset...\")\n",
    "            return create_sample_dataset(n_samples)\n",
    "        \n",
    "        # Load the data\n",
    "        if sample_size:\n",
    "            # Load a random sample of rows\n",
    "            df = pd.read_csv(file_path, nrows=sample_size)\n",
    "            print(f\"Loaded {len(df)} rows (sample) from {file_path}\")\n",
    "        else:\n",
    "            # Load the entire dataset\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Loaded {len(df)} rows from {file_path}\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        print(\"Creating sample dataset instead...\")\n",
    "        return create_sample_dataset(n_samples)\n",
    "\n",
    "def create_sample_dataset(n_samples=1000):\n",
    "    \"\"\"\n",
    "    Create a sample dataset for demonstration purposes.\n",
    "    \n",
    "    Args:\n",
    "        n_samples (int): Number of samples to generate\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Sample DataFrame\n",
    "    \"\"\"\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    \n",
    "    # Create sample features\n",
    "    sample_data = {\n",
    "        'Dst Port': np.random.randint(1, 65536, n_samples),\n",
    "        'Protocol': np.random.choice([0, 6, 17], n_samples),  # 0=ICMP, 6=TCP, 17=UDP\n",
    "        'Flow Duration': np.random.randint(1, 100000, n_samples),\n",
    "        'Tot Fwd Pkts': np.random.randint(1, 100, n_samples),\n",
    "        'Tot Bwd Pkts': np.random.randint(1, 100, n_samples),\n",
    "        'TotLen Fwd Pkts': np.random.randint(1, 10000, n_samples),\n",
    "        'TotLen Bwd Pkts': np.random.randint(1, 10000, n_samples),\n",
    "        'Fwd Pkt Len Max': np.random.randint(1, 1500, n_samples),\n",
    "        'Fwd Pkt Len Min': np.random.randint(0, 100, n_samples),\n",
    "        'Fwd Pkt Len Mean': np.random.uniform(10, 500, n_samples),\n",
    "        'Bwd Pkt Len Max': np.random.randint(1, 1500, n_samples),\n",
    "        'Bwd Pkt Len Min': np.random.randint(0, 100, n_samples),\n",
    "        'Bwd Pkt Len Mean': np.random.uniform(10, 500, n_samples),\n",
    "        'Flow Byts/s': np.random.uniform(0, 10000, n_samples),\n",
    "        'Flow Pkts/s': np.random.uniform(0, 1000, n_samples),\n",
    "        'Flow IAT Mean': np.random.uniform(0, 1000, n_samples),\n",
    "        'Flow IAT Std': np.random.uniform(0, 500, n_samples),\n",
    "        'Flow IAT Max': np.random.uniform(0, 2000, n_samples),\n",
    "        'Flow IAT Min': np.random.uniform(0, 100, n_samples),\n",
    "        'Fwd Header Length.1': np.random.randint(20, 100, n_samples),  # Duplicate column\n",
    "        'Fwd Header Length': np.random.randint(20, 100, n_samples),\n",
    "        'Label': np.random.choice(['Benign', 'DoS Hulk', 'PortScan', 'Brute Force-Web', 'Web Attack'], n_samples, \n",
    "                                 p=[0.7, 0.1, 0.1, 0.05, 0.05])\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(f\"Created sample dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, normalize_names=True, remove_duplicates=True, \n",
    "                   encode_categorical=True, handle_missing=True, \n",
    "                   handle_negative=True, remove_outliers=False,\n",
    "                   scale_features=True):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset with various cleaning and transformation steps.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        normalize_names (bool): Whether to normalize column names\n",
    "        remove_duplicates (bool): Whether to remove duplicate columns\n",
    "        encode_categorical (bool): Whether to encode categorical features\n",
    "        handle_missing (bool): Whether to handle missing values\n",
    "        handle_negative (bool): Whether to handle negative values\n",
    "        remove_outliers (bool): Whether to remove outliers\n",
    "        scale_features (bool): Whether to scale numerical features\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame\n",
    "        dict: Dictionary of preprocessing artifacts (encoders, scalers, etc.)\n",
    "    \"\"\"\n",
    "    print(\"Starting data preprocessing...\")\n",
    "    artifacts = {}\n",
    "    \n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Step 1: Normalize column names\n",
    "    if normalize_names:\n",
    "        df_processed = normalize_column_names(df_processed)\n",
    "    \n",
    "    # Step 2: Remove duplicate columns\n",
    "    if remove_duplicates:\n",
    "        df_processed = remove_duplicate_columns(df_processed)\n",
    "    \n",
    "    # Step 3: Encode categorical features\n",
    "    if encode_categorical:\n",
    "        df_processed, label_encoders = encode_categorical_features(df_processed)\n",
    "        artifacts['label_encoders'] = label_encoders\n",
    "    \n",
    "    # Step 4: Handle missing values (NaN and infinite values)\n",
    "    if handle_missing:\n",
    "        # Replace infinite values with NaN\n",
    "        df_processed = replace_inf_with_nan(df_processed)\n",
    "        \n",
    "        # Impute missing values\n",
    "        df_processed = impute_missing_values(df_processed)\n",
    "    \n",
    "    # Step 5: Handle negative values in columns that should be non-negative\n",
    "    if handle_negative:\n",
    "        df_processed = replace_negative_values(df_processed)\n",
    "    \n",
    "    # Step 6: Remove outliers\n",
    "    if remove_outliers:\n",
    "        df_processed = remove_outliers_isolation_forest(df_processed)\n",
    "    \n",
    "    # Step 7: Scale numerical features\n",
    "    if scale_features:\n",
    "        df_processed, scaler = scale_numerical_features(df_processed)\n",
    "        artifacts['scaler'] = scaler\n",
    "    \n",
    "    print(f\"Data preprocessing complete. Final shape: {df_processed.shape}\")\n",
    "    return df_processed, artifacts\n",
    "\n",
    "def normalize_column_names(df):\n",
    "    \"\"\"\n",
    "    Normalize column names by removing leading/trailing whitespace,\n",
    "    replacing spaces with underscores, and converting to lowercase.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with normalized column names\n",
    "    \"\"\"\n",
    "    print(\"Normalizing column names...\")\n",
    "    \n",
    "    # Store original column names for reference\n",
    "    original_columns = df.columns.tolist()\n",
    "    \n",
    "    # Normalize column names\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "    \n",
    "    # Print mapping of original to normalized column names\n",
    "    changed_columns = sum(1 for orig, norm in zip(original_columns, df.columns) if orig != norm)\n",
    "    print(f\"Normalized {changed_columns} column names\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_duplicate_columns(df):\n",
    "    \"\"\"\n",
    "    Identify and remove duplicate columns from the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicate columns removed\n",
    "    \"\"\"\n",
    "    print(\"Checking for duplicate columns...\")\n",
    "    \n",
    "    # Get list of all columns\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    # Initialize list to store duplicate columns\n",
    "    duplicate_columns = []\n",
    "    \n",
    "    # Check for columns ending with '.1', '.2', etc.\n",
    "    for col in columns:\n",
    "        if col.endswith(('.1', '.2', '.3', '.4', '.5')):\n",
    "            base_col = col.rsplit('.', 1)[0]\n",
    "            if base_col in columns:\n",
    "                # Check if the columns are actually duplicates\n",
    "                if df[col].equals(df[base_col]):\n",
    "                    duplicate_columns.append(col)\n",
    "                    print(f\"Found duplicate column: {col} (duplicate of {base_col})\")\n",
    "    \n",
    "    # Check for duplicate columns with different names\n",
    "    for i, col1 in enumerate(columns):\n",
    "        for col2 in columns[i+1:]:\n",
    "            if col1 not in duplicate_columns and col2 not in duplicate_columns:\n",
    "                if df[col1].equals(df[col2]):\n",
    "                    duplicate_columns.append(col2)\n",
    "                    print(f\"Found duplicate column: {col2} (duplicate of {col1})\")\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    if duplicate_columns:\n",
    "        df = df.drop(columns=duplicate_columns)\n",
    "        print(f\"Removed {len(duplicate_columns)} duplicate columns\")\n",
    "    else:\n",
    "        print(\"No duplicate columns found\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    \"\"\"\n",
    "    Encode categorical features using Label Encoding.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded categorical features\n",
    "        dict: Dictionary mapping column names to their respective label encoders\n",
    "    \"\"\"\n",
    "    print(\"Encoding categorical features...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Initialize dictionary to store label encoders\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Identify categorical columns (excluding the target variable)\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if 'label' in categorical_columns:\n",
    "        categorical_columns.remove('label')\n",
    "    \n",
    "    print(f\"Found {len(categorical_columns)} categorical columns\")\n",
    "    \n",
    "    # Encode each categorical column\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Handle the target variable separately\n",
    "    if 'label' in df.columns and df['label'].dtype in ['object', 'category']:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded['label'] = le.fit_transform(df['label'].astype(str))\n",
    "        label_encoders['label'] = le\n",
    "        print(f\"Encoded target variable 'label' with {len(le.classes_)} classes\")\n",
    "    \n",
    "    return df_encoded, label_encoders\n",
    "\n",
    "def replace_inf_with_nan(df):\n",
    "    \"\"\"\n",
    "    Replace infinite values with NaN in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with infinite values replaced with NaN\n",
    "    \"\"\"\n",
    "    print(\"Replacing infinite values with NaN...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_no_inf = df.copy()\n",
    "    \n",
    "    # Replace infinite values with NaN\n",
    "    df_no_inf = df_no_inf.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Count NaN values after replacement\n",
    "    nan_counts = df_no_inf.isna().sum()\n",
    "    nan_columns = nan_counts[nan_counts > 0]\n",
    "    \n",
    "    if len(nan_columns) > 0:\n",
    "        print(f\"Found {nan_columns.sum()} NaN values across {len(nan_columns)} columns\")\n",
    "    else:\n",
    "        print(\"No infinite values found\")\n",
    "    \n",
    "    return df_no_inf\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values (NaN) with the column median for numerical features\n",
    "    and the most frequent value for categorical features.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed\n",
    "    \"\"\"\n",
    "    print(\"Imputing missing values...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    # Get list of numerical and categorical columns\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Impute missing values in numerical columns with median\n",
    "    for col in numerical_columns:\n",
    "        if df_imputed[col].isna().any():\n",
    "            median_value = df_imputed[col].median()\n",
    "            df_imputed[col] = df_imputed[col].fillna(median_value)\n",
    "            print(f\"Imputed missing values in '{col}' with median: {median_value:.4f}\")\n",
    "    \n",
    "    # Impute missing values in categorical columns with most frequent value\n",
    "    for col in categorical_columns:\n",
    "        if df_imputed[col].isna().any():\n",
    "            most_frequent = df_imputed[col].mode()[0]\n",
    "            df_imputed[col] = df_imputed[col].fillna(most_frequent)\n",
    "            print(f\"Imputed missing values in '{col}' with most frequent value: {most_frequent}\")\n",
    "    \n",
    "    # Verify that there are no more missing values\n",
    "    nan_counts = df_imputed.isna().sum()\n",
    "    if nan_counts.sum() > 0:\n",
    "        print(\"Warning: There are still missing values in the DataFrame\")\n",
    "        print(nan_counts[nan_counts > 0])\n",
    "    else:\n",
    "        print(\"All missing values have been imputed\")\n",
    "    \n",
    "    return df_imputed\n",
    "\n",
    "def replace_negative_values(df):\n",
    "    \"\"\"\n",
    "    Replace nonsensical negative values in specific columns with the median.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with nonsensical negative values replaced\n",
    "    \"\"\"\n",
    "    print(\"Checking for negative values in columns that should be non-negative...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_no_neg = df.copy()\n",
    "    \n",
    "    # List of columns that should not have negative values\n",
    "    # These are typically columns representing counts, durations, lengths, etc.\n",
    "    non_negative_columns = [\n",
    "        col for col in df.columns if any(keyword in col.lower() for keyword in \n",
    "                                        ['duration', 'length', 'packets', 'bytes', 'count', 'min', 'max', 'mean'])\n",
    "    ]\n",
    "    \n",
    "    # Replace negative values with the median in each column\n",
    "    replaced_count = 0\n",
    "    for col in non_negative_columns:\n",
    "        if col in df_no_neg.columns and df_no_neg[col].dtype in ['int64', 'float64'] and (df_no_neg[col] < 0).any():\n",
    "            neg_count = (df_no_neg[col] < 0).sum()\n",
    "            median_value = df_no_neg[df_no_neg[col] >= 0][col].median()\n",
    "            df_no_neg.loc[df_no_neg[col] < 0, col] = median_value\n",
    "            replaced_count += neg_count\n",
    "            print(f\"Replaced {neg_count} negative values in '{col}' with median: {median_value:.4f}\")\n",
    "    \n",
    "    if replaced_count == 0:\n",
    "        print(\"No negative values found in columns that should be non-negative\")\n",
    "    else:\n",
    "        print(f\"Replaced a total of {replaced_count} negative values\")\n",
    "    \n",
    "    return df_no_neg\n",
    "\n",
    "def remove_outliers_isolation_forest(df, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Detect and remove outliers using the Isolation Forest algorithm.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        contamination (float): The proportion of outliers in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers removed\n",
    "    \"\"\"\n",
    "    print(f\"Detecting outliers using Isolation Forest (contamination={contamination})...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_no_outliers = df.copy()\n",
    "    \n",
    "    # Get list of all columns except the target variable\n",
    "    X = df.drop(columns=['label'] if 'label' in df.columns else [])\n",
    "    \n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    isolation_forest = IsolationForest(contamination=contamination, random_state=RANDOM_STATE)\n",
    "    outlier_pred = isolation_forest.fit_predict(X)\n",
    "    \n",
    "    # Count outliers\n",
    "    outlier_count = (outlier_pred == -1).sum()\n",
    "    print(f\"Detected {outlier_count} outliers ({outlier_count/len(df)*100:.2f}% of the dataset)\")\n",
    "    \n",
    "    # Remove outliers\n",
    "    df_no_outliers = df_no_outliers[outlier_pred == 1]\n",
    "    print(f\"DataFrame shape after removing outliers: {df_no_outliers.shape}\")\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "def scale_numerical_features(df):\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with scaled numerical features\n",
    "        StandardScaler: Fitted scaler object\n",
    "    \"\"\"\n",
    "    print(\"Scaling numerical features...\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # Get list of numerical columns except the target variable\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if 'label' in numerical_columns:\n",
    "        numerical_columns.remove('label')\n",
    "    \n",
    "    # Initialize and fit the scaler\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    \n",
    "    print(f\"Scaled {len(numerical_columns)} numerical features\")\n",
    "    \n",
    "    return df_scaled, scaler\n",
    "\n",
    "# <a id=\"eda\"></a>\n",
    "# ## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec22877",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def perform_eda(df, target_col='label'):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis on the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        target_col (str): Name of the target column\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing EDA results\n",
    "    \"\"\"\n",
    "    print(\"Performing exploratory data analysis...\")\n",
    "    \n",
    "    eda_results = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"Calculating basic statistics...\")\n",
    "    eda_results['basic_stats'] = df.describe()\n",
    "    \n",
    "    # Class distribution\n",
    "    if target_col in df.columns:\n",
    "        print(\"Analyzing class distribution...\")\n",
    "        class_counts = df[target_col].value_counts()\n",
    "        class_percentages = class_counts / len(df) * 100\n",
    "        \n",
    "        eda_results['class_distribution'] = {\n",
    "            'counts': class_counts,\n",
    "            'percentages': class_percentages\n",
    "        }\n",
    "        \n",
    "        # Plot class distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "        plt.title('Class Distribution')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add count labels on top of bars\n",
    "        for i, count in enumerate(class_counts.values):\n",
    "            ax.text(i, count + 0.1, f'{count} ({class_percentages[i]:.1f}%)', \n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Correlation analysis\n",
    "    print(\"Calculating feature correlations...\")\n",
    "    numerical_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "    if len(numerical_df.columns) > 1:  # Need at least 2 columns for correlation\n",
    "        correlation_matrix = numerical_df.corr()\n",
    "        eda_results['correlation_matrix'] = correlation_matrix\n",
    "        \n",
    "        # Plot correlation heatmap\n",
    "        plt.figure(figsize=(14, 12))\n",
    "        mask = np.triu(correlation_matrix)\n",
    "        sns.heatmap(correlation_matrix, annot=False, mask=mask, cmap='coolwarm', \n",
    "                    linewidths=0.5, vmin=-1, vmax=1)\n",
    "        plt.title('Feature Correlation Heatmap')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Find highly correlated features\n",
    "        high_corr_threshold = 0.8\n",
    "        high_corr_features = []\n",
    "        \n",
    "        for i in range(len(correlation_matrix.columns)):\n",
    "            for j in range(i+1, len(correlation_matrix.columns)):\n",
    "                if abs(correlation_matrix.iloc[i, j]) > high_corr_threshold:\n",
    "                    high_corr_features.append((\n",
    "                        correlation_matrix.columns[i],\n",
    "                        correlation_matrix.columns[j],\n",
    "                        correlation_matrix.iloc[i, j]\n",
    "                    ))\n",
    "        \n",
    "        eda_results['high_corr_features'] = high_corr_features\n",
    "        \n",
    "        if high_corr_features:\n",
    "            print(f\"Found {len(high_corr_features)} pairs of highly correlated features (|r| > {high_corr_threshold}):\")\n",
    "            for feat1, feat2, corr in high_corr_features[:10]:  # Show top 10\n",
    "                print(f\"  {feat1} and {feat2}: r = {corr:.4f}\")\n",
    "            if len(high_corr_features) > 10:\n",
    "                print(f\"  ... and {len(high_corr_features) - 10} more\")\n",
    "    \n",
    "    # Feature distributions\n",
    "    print(\"Analyzing feature distributions...\")\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if target_col in numerical_columns:\n",
    "        numerical_columns.remove(target_col)\n",
    "    \n",
    "    # Sample a subset of numerical features if there are too many\n",
    "    if len(numerical_columns) > 6:\n",
    "        sampled_columns = np.random.choice(numerical_columns, 6, replace=False)\n",
    "    else:\n",
    "        sampled_columns = numerical_columns\n",
    "    \n",
    "    if sampled_columns.size > 0:\n",
    "        # Plot distributions of sampled features\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, col in enumerate(sampled_columns):\n",
    "            if i < len(axes):\n",
    "                sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "                axes[i].set_title(f'Distribution of {col}')\n",
    "                axes[i].set_xlabel(col)\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # PCA visualization if there are enough numerical features\n",
    "    if len(numerical_columns) >= 3:\n",
    "        print(\"Performing PCA visualization...\")\n",
    "        # Select numerical features for PCA\n",
    "        X = df[numerical_columns]\n",
    "        \n",
    "        # Standardize the features\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=3)\n",
    "        principal_components = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # Create a DataFrame with the principal components\n",
    "        pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2', 'PC3'])\n",
    "        \n",
    "        # Add the target variable\n",
    "        if target_col in df.columns:\n",
    "            pca_df[target_col] = df[target_col].values\n",
    "            \n",
    "            # Plot PCA results\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df[target_col].astype('category').cat.codes, \n",
    "                                 alpha=0.6, cmap='viridis')\n",
    "            plt.title('PCA: First Two Principal Components')\n",
    "            plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "            plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "            plt.colorbar(scatter, label=target_col)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 3D PCA plot\n",
    "            fig = plt.figure(figsize=(10, 8))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            scatter = ax.scatter(pca_df['PC1'], pca_df['PC2'], pca_df['PC3'], \n",
    "                               c=pca_df[target_col].astype('category').cat.codes, \n",
    "                               alpha=0.6, cmap='viridis')\n",
    "            ax.set_title('PCA: First Three Principal Components')\n",
    "            ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "            ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "            ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})')\n",
    "            plt.colorbar(scatter, label=target_col)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Store PCA results\n",
    "        eda_results['pca'] = {\n",
    "            'pca_object': pca,\n",
    "            'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "            'cumulative_variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "        }\n",
    "        \n",
    "        print(f\"PCA explained variance: {pca.explained_variance_ratio_}\")\n",
    "        print(f\"Cumulative explained variance: {np.cumsum(pca.explained_variance_ratio_)}\")\n",
    "    \n",
    "    print(\"Exploratory data analysis complete\")\n",
    "    return eda_results\n",
    "\n",
    "# <a id=\"feature_engineering\"></a>\n",
    "# ## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb2950",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def engineer_features(df, target_col='label', correlation_threshold=0.1, \n",
    "                     n_features=None, feature_selection_method='correlation'):\n",
    "    \"\"\"\n",
    "    Perform feature engineering on the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        target_col (str): Name of the target column\n",
    "        correlation_threshold (float): Minimum absolute correlation with target for feature selection\n",
    "        n_features (int, optional): Number of features to select (if None, use correlation_threshold)\n",
    "        feature_selection_method (str): Method for feature selection ('correlation', 'selectkbest', 'rfe')\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with selected features\n",
    "        list: List of selected feature names\n",
    "    \"\"\"\n",
    "    print(\"Performing feature engineering...\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    if target_col in df.columns:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        X = df.copy()\n",
    "        y = None\n",
    "        print(f\"Warning: Target column '{target_col}' not found in DataFrame\")\n",
    "        return df, df.columns.tolist()\n",
    "    \n",
    "    # Get numerical feature names\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Feature selection based on correlation with target\n",
    "    if feature_selection_method == 'correlation' and y is not None:\n",
    "        print(f\"Selecting features based on correlation with target (threshold={correlation_threshold})...\")\n",
    "        \n",
    "        # Calculate correlation with target for each feature\n",
    "        correlations = []\n",
    "        for col in numerical_features:\n",
    "            corr = np.corrcoef(X[col], y)[0, 1]\n",
    "            correlations.append((col, abs(corr)))\n",
    "        \n",
    "        # Sort features by absolute correlation\n",
    "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select features based on threshold or number\n",
    "        if n_features is not None:\n",
    "            selected_features = [col for col, _ in correlations[:n_features]]\n",
    "            print(f\"Selected top {len(selected_features)} features based on correlation with target\")\n",
    "        else:\n",
    "            selected_features = [col for col, corr in correlations if corr >= correlation_threshold]\n",
    "            print(f\"Selected {len(selected_features)} features with |correlation| >= {correlation_threshold}\")\n",
    "        \n",
    "        # Print top correlations\n",
    "        print(\"Top feature correlations with target:\")\n",
    "        for col, corr in correlations[:10]:\n",
    "            print(f\"  {col}: |r| = {corr:.4f}\")\n",
    "    \n",
    "    # Feature selection using SelectKBest\n",
    "    elif feature_selection_method == 'selectkbest' and y is not None:\n",
    "        n_features = n_features or min(10, len(numerical_features))\n",
    "        print(f\"Selecting top {n_features} features using SelectKBest (f_classif)...\")\n",
    "        \n",
    "        # Initialize and fit SelectKBest\n",
    "        selector = SelectKBest(f_classif, k=n_features)\n",
    "        selector.fit(X[numerical_features], y)\n",
    "        \n",
    "        # Get selected feature indices and names\n",
    "        selected_indices = selector.get_support(indices=True)\n",
    "        selected_features = [numerical_features[i] for i in selected_indices]\n",
    "        \n",
    "        # Print selected features and their scores\n",
    "        feature_scores = list(zip(numerical_features, selector.scores_))\n",
    "        feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"Top feature scores:\")\n",
    "        for col, score in feature_scores[:10]:\n",
    "            print(f\"  {col}: score = {score:.4f}\")\n",
    "    \n",
    "    # Feature selection using RFE with Random Forest\n",
    "    elif feature_selection_method == 'rfe' and y is not None:\n",
    "        n_features = n_features or min(10, len(numerical_features))\n",
    "        print(f\"Selecting top {n_features} features using RFE with Random Forest...\")\n",
    "        \n",
    "        # Initialize and fit RFE\n",
    "        estimator = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "        selector = RFE(estimator, n_features_to_select=n_features, step=1)\n",
    "        selector.fit(X[numerical_features], y)\n",
    "        \n",
    "        # Get selected feature names\n",
    "        selected_features = [numerical_features[i] for i, selected in enumerate(selector.support_) if selected]\n",
    "        \n",
    "        print(f\"Selected {len(selected_features)} features using RFE\")\n",
    "    \n",
    "    else:\n",
    "        # If no valid feature selection method or no target, use all features\n",
    "        selected_features = X.columns.tolist()\n",
    "        print(f\"Using all {len(selected_features)} features (no feature selection applied)\")\n",
    "    \n",
    "    # Add target column back to selected features\n",
    "    if target_col not in selected_features and target_col in df.columns:\n",
    "        selected_features.append(target_col)\n",
    "    \n",
    "    # Create DataFrame with selected features\n",
    "    df_selected = df[selected_features].copy()\n",
    "    \n",
    "    print(f\"Feature engineering complete. Selected {len(selected_features)} features\")\n",
    "    return df_selected, selected_features\n",
    "\n",
    "# <a id=\"ml_models\"></a>\n",
    "# ## 5. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388727d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_data(df, target_col='label', test_size=0.2, val_size=0.25):\n",
    "    \"\"\"\n",
    "    Split the dataset into training, validation, and test sets.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        target_col (str): Name of the target column\n",
    "        test_size (float): Proportion of data to use for testing\n",
    "        val_size (float): Proportion of training data to use for validation\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    \"\"\"\n",
    "    print(f\"Splitting data into train, validation, and test sets...\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    if target_col in df.columns:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found in DataFrame\")\n",
    "    \n",
    "    # First split: training + validation vs. test\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Second split: training vs. validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size, random_state=RANDOM_STATE, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    print(f\"Data split complete:\")\n",
    "    print(f\"  Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df):.1%})\")\n",
    "    print(f\"  Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(df):.1%})\")\n",
    "    print(f\"  Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df):.1%})\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def train_models(X_train, y_train, X_val, y_val, models_to_train=None):\n",
    "    \"\"\"\n",
    "    Train multiple machine learning models on the dataset.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features\n",
    "        y_train (pd.Series): Training target\n",
    "        X_val (pd.DataFrame): Validation features\n",
    "        y_val (pd.Series): Validation target\n",
    "        models_to_train (list, optional): List of model names to train\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of trained models and their performance metrics\n",
    "    \"\"\"\n",
    "    print(\"Training machine learning models...\")\n",
    "    \n",
    "    # Define available models\n",
    "    available_models = {\n",
    "        'random_forest': {\n",
    "            'name': 'Random Forest',\n",
    "            'model': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "        },\n",
    "        'gradient_boosting': {\n",
    "            'name': 'Gradient Boosting',\n",
    "            'model': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 5, 7]\n",
    "            }\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'name': 'XGBoost',\n",
    "            'model': xgb.XGBClassifier(random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 5, 7]\n",
    "            }\n",
    "        },\n",
    "        'lightgbm': {\n",
    "            'name': 'LightGBM',\n",
    "            'model': lgb.LGBMClassifier(random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 5, 7]\n",
    "            }\n",
    "        },\n",
    "        'logistic_regression': {\n",
    "            'name': 'Logistic Regression',\n",
    "            'model': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'C': [0.1, 1.0, 10.0],\n",
    "                'solver': ['liblinear', 'lbfgs']\n",
    "            }\n",
    "        },\n",
    "        'svm': {\n",
    "            'name': 'Support Vector Machine',\n",
    "            'model': SVC(probability=True, random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'C': [0.1, 1.0, 10.0],\n",
    "                'kernel': ['linear', 'rbf'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "            }\n",
    "        },\n",
    "        'knn': {\n",
    "            'name': 'K-Nearest Neighbors',\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'params': {\n",
    "                'n_neighbors': [3, 5, 7, 9],\n",
    "                'weights': ['uniform', 'distance']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'name': 'Decision Tree',\n",
    "            'model': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "            'params': {\n",
    "                'max_depth': [None, 10, 20, 30],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add neural network model if TensorFlow is available\n",
    "    if TENSORFLOW_AVAILABLE:\n",
    "        available_models['neural_network'] = {\n",
    "            'name': 'Neural Network',\n",
    "            'model': None,  # Will be created during training\n",
    "            'params': {}  # No hyperparameter tuning for neural network\n",
    "        }\n",
    "    \n",
    "    # Select models to train\n",
    "    if models_to_train is None:\n",
    "        # Train all available models\n",
    "        models_to_train = list(available_models.keys())\n",
    "    else:\n",
    "        # Validate requested models\n",
    "        for model_name in models_to_train:\n",
    "            if model_name not in available_models:\n",
    "                print(f\"Warning: Model '{model_name}' not found. Available models: {list(available_models.keys())}\")\n",
    "                models_to_train.remove(model_name)\n",
    "    \n",
    "    # Initialize dictionary to store trained models and their metrics\n",
    "    trained_models = {}\n",
    "    \n",
    "    # Train each selected model\n",
    "    for model_name in models_to_train:\n",
    "        print(f\"\\nTraining {available_models[model_name]['name']}...\")\n",
    "        \n",
    "        # Special case for neural network\n",
    "        if model_name == 'neural_network' and TENSORFLOW_AVAILABLE:\n",
    "            # Create and train neural network\n",
    "            model, history = train_neural_network(X_train, y_train, X_val, y_val)\n",
    "            \n",
    "            # Make predictions on validation set\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_val, y_val_pred_classes)\n",
    "            precision = precision_score(y_val, y_val_pred_classes, average='weighted')\n",
    "            recall = recall_score(y_val, y_val_pred_classes, average='weighted')\n",
    "            f1 = f1_score(y_val, y_val_pred_classes, average='weighted')\n",
    "            \n",
    "            # Store model and metrics\n",
    "            trained_models[model_name] = {\n",
    "                'name': available_models[model_name]['name'],\n",
    "                'model': model,\n",
    "                'metrics': {\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1': f1\n",
    "                },\n",
    "                'history': history\n",
    "            }\n",
    "            \n",
    "            print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"  Validation F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        else:\n",
    "            # Get model and hyperparameters\n",
    "            model_info = available_models[model_name]\n",
    "            model = model_info['model']\n",
    "            params = model_info['params']\n",
    "            \n",
    "            # Train model with cross-validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "            grid_search = GridSearchCV(\n",
    "                model, params, cv=cv, scoring='f1_weighted', n_jobs=-1, verbose=0\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                grid_search.fit(X_train, y_train)\n",
    "                \n",
    "                # Get best model\n",
    "                best_model = grid_search.best_estimator_\n",
    "                \n",
    "                # Make predictions on validation set\n",
    "                y_val_pred = best_model.predict(X_val)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(y_val, y_val_pred)\n",
    "                precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "                recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "                f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "                \n",
    "                # Store model and metrics\n",
    "                trained_models[model_name] = {\n",
    "                    'name': model_info['name'],\n",
    "                    'model': best_model,\n",
    "                    'metrics': {\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1\n",
    "                    },\n",
    "                    'best_params': grid_search.best_params_,\n",
    "                    'cv_results': grid_search.cv_results_\n",
    "                }\n",
    "                \n",
    "                print(f\"  Best Parameters: {grid_search.best_params_}\")\n",
    "                print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"  Validation F1 Score: {f1:.4f}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  Error training {model_info['name']}: {e}\")\n",
    "    \n",
    "    print(\"\\nModel training complete\")\n",
    "    return trained_models\n",
    "\n",
    "def train_neural_network(X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train a neural network model for classification.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features\n",
    "        y_train (pd.Series): Training target\n",
    "        X_val (pd.DataFrame): Validation features\n",
    "        y_val (pd.Series): Validation target\n",
    "        epochs (int): Number of training epochs\n",
    "        batch_size (int): Batch size for training\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, training_history)\n",
    "    \"\"\"\n",
    "    if not TENSORFLOW_AVAILABLE:\n",
    "        print(\"TensorFlow not available. Cannot train neural network.\")\n",
    "        return None, None\n",
    "    \n",
    "    print(\"Training neural network...\")\n",
    "    \n",
    "    # Convert target to one-hot encoding\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val_onehot = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "    \n",
    "    # Define model architecture\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Define early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train_onehot,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val_onehot),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Neural network training complete after {len(history.history['loss'])} epochs\")\n",
    "    print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# <a id=\"evaluation\"></a>\n",
    "# ## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a67484",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_models(trained_models, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate trained models on the test set.\n",
    "    \n",
    "    Args:\n",
    "        trained_models (dict): Dictionary of trained models\n",
    "        X_test (pd.DataFrame): Test features\n",
    "        y_test (pd.Series): Test target\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of evaluation results\n",
    "    \"\"\"\n",
    "    print(\"Evaluating models on test set...\")\n",
    "    \n",
    "    # Initialize dictionary to store evaluation results\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model_name, model_info in trained_models.items():\n",
    "        print(f\"\\nEvaluating {model_info['name']}...\")\n",
    "        \n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Special case for neural network\n",
    "        if model_name == 'neural_network' and TENSORFLOW_AVAILABLE:\n",
    "            # Make predictions\n",
    "            y_pred_proba = model.predict(X_test)\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        else:\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Get prediction probabilities if available\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                y_pred_proba = model.predict_proba(X_test)\n",
    "            else:\n",
    "                y_pred_proba = None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Generate classification report\n",
    "        cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Store evaluation results\n",
    "        evaluation_results[model_name] = {\n",
    "            'name': model_info['name'],\n",
    "            'metrics': {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1\n",
    "            },\n",
    "            'confusion_matrix': cm,\n",
    "            'classification_report': cr,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"  Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Test Precision: {precision:.4f}\")\n",
    "        print(f\"  Test Recall: {recall:.4f}\")\n",
    "        print(f\"  Test F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=np.unique(y_test), \n",
    "                   yticklabels=np.unique(y_test))\n",
    "        plt.title(f'Confusion Matrix - {model_info[\"name\"]}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot ROC curve for binary classification\n",
    "        if len(np.unique(y_test)) == 2 and y_pred_proba is not None:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            \n",
    "            # Calculate ROC curve and AUC\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve - {model_info[\"name\"]}')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Store ROC curve data\n",
    "            evaluation_results[model_name]['roc_curve'] = {\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'auc': roc_auc\n",
    "            }\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    model_comparison = {\n",
    "        'Model': [],\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        model_comparison['Model'].append(results['name'])\n",
    "        model_comparison['Accuracy'].append(results['metrics']['accuracy'])\n",
    "        model_comparison['Precision'].append(results['metrics']['precision'])\n",
    "        model_comparison['Recall'].append(results['metrics']['recall'])\n",
    "        model_comparison['F1 Score'].append(results['metrics']['f1'])\n",
    "    \n",
    "    # Create DataFrame for comparison\n",
    "    comparison_df = pd.DataFrame(model_comparison)\n",
    "    comparison_df = comparison_df.sort_values('F1 Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create bar chart\n",
    "    x = np.arange(len(comparison_df))\n",
    "    width = 0.2\n",
    "    \n",
    "    plt.bar(x - 1.5*width, comparison_df['Accuracy'], width, label='Accuracy')\n",
    "    plt.bar(x - 0.5*width, comparison_df['Precision'], width, label='Precision')\n",
    "    plt.bar(x + 0.5*width, comparison_df['Recall'], width, label='Recall')\n",
    "    plt.bar(x + 1.5*width, comparison_df['F1 Score'], width, label='F1 Score')\n",
    "    \n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Comparison')\n",
    "    plt.xticks(x, comparison_df['Model'], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nModel evaluation complete\")\n",
    "    return evaluation_results\n",
    "\n",
    "# <a id=\"deployment\"></a>\n",
    "# ## 7. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede0175",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model, model_name, artifacts=None, output_dir='models'):\n",
    "    \"\"\"\n",
    "    Save a trained model and its artifacts for deployment.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model object\n",
    "        model_name (str): Name of the model\n",
    "        artifacts (dict, optional): Dictionary of model artifacts (e.g., scaler, encoders)\n",
    "        output_dir (str): Directory to save the model\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the saved model\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    import os\n",
    "    \n",
    "    print(f\"Saving model: {model_name}...\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(output_dir, f\"{model_name}.pkl\")\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # Save artifacts if provided\n",
    "    if artifacts:\n",
    "        artifacts_path = os.path.join(output_dir, f\"{model_name}_artifacts.pkl\")\n",
    "        with open(artifacts_path, 'wb') as f:\n",
    "            pickle.dump(artifacts, f)\n",
    "        print(f\"Model artifacts saved to: {artifacts_path}\")\n",
    "    \n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "    return model_path\n",
    "\n",
    "def load_model(model_path, artifacts_path=None):\n",
    "    \"\"\"\n",
    "    Load a saved model and its artifacts.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model\n",
    "        artifacts_path (str, optional): Path to the saved artifacts\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (model, artifacts)\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    print(f\"Loading model from: {model_path}...\")\n",
    "    \n",
    "    # Load model\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Load artifacts if provided\n",
    "    artifacts = None\n",
    "    if artifacts_path:\n",
    "        with open(artifacts_path, 'rb') as f:\n",
    "            artifacts = pickle.load(f)\n",
    "        print(f\"Model artifacts loaded from: {artifacts_path}\")\n",
    "    \n",
    "    print(\"Model loaded successfully\")\n",
    "    return model, artifacts\n",
    "\n",
    "def create_prediction_pipeline(model, artifacts=None):\n",
    "    \"\"\"\n",
    "    Create a prediction pipeline for the model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model object\n",
    "        artifacts (dict, optional): Dictionary of model artifacts\n",
    "        \n",
    "    Returns:\n",
    "        function: Prediction function\n",
    "    \"\"\"\n",
    "    def predict(data):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \n",
    "        Args:\n",
    "            data (pd.DataFrame or dict): Input data for prediction\n",
    "            \n",
    "        Returns:\n",
    "            dict: Prediction results\n",
    "        \"\"\"\n",
    "        # Convert dictionary to DataFrame if necessary\n",
    "        if isinstance(data, dict):\n",
    "            data = pd.DataFrame([data])\n",
    "        \n",
    "        # Preprocess data if artifacts are provided\n",
    "        if artifacts:\n",
    "            # Apply label encoding to categorical features\n",
    "            if 'label_encoders' in artifacts:\n",
    "                for col, encoder in artifacts['label_encoders'].items():\n",
    "                    if col in data.columns and col != 'label':\n",
    "                        data[col] = encoder.transform(data[col].astype(str))\n",
    "            \n",
    "            # Apply scaling to numerical features\n",
    "            if 'scaler' in artifacts:\n",
    "                numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "                data[numerical_columns] = artifacts['scaler'].transform(data[numerical_columns])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(data)\n",
    "        \n",
    "        # Get prediction probabilities if available\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probabilities = model.predict_proba(data)\n",
    "        else:\n",
    "            probabilities = None\n",
    "        \n",
    "        # Decode prediction if label encoder is available\n",
    "        if artifacts and 'label_encoders' in artifacts and 'label' in artifacts['label_encoders']:\n",
    "            prediction = artifacts['label_encoders']['label'].inverse_transform(prediction)\n",
    "        \n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            'prediction': prediction.tolist(),\n",
    "            'probabilities': probabilities.tolist() if probabilities is not None else None\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return predict\n",
    "\n",
    "# <a id=\"main\"></a>\n",
    "# ## 8. Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c43800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the complete machine learning pipeline.\n",
    "    \"\"\"\n",
    "    print(\"Starting Network Intrusion Detection ML Pipeline...\")\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    df = load_data(sample_size=10000)  # Adjust sample size as needed\n",
    "    \n",
    "    # Step 2: Preprocess data\n",
    "    df_processed, artifacts = preprocess_data(df)\n",
    "    \n",
    "    # Step 3: Perform exploratory data analysis\n",
    "    eda_results = perform_eda(df_processed)\n",
    "    \n",
    "    # Step 4: Engineer features\n",
    "    df_selected, selected_features = engineer_features(df_processed)\n",
    "    \n",
    "    # Step 5: Split data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df_selected)\n",
    "    \n",
    "    # Step 6: Train models\n",
    "    # Select a subset of models for faster execution\n",
    "    models_to_train = ['random_forest', 'gradient_boosting', 'logistic_regression']\n",
    "    trained_models = train_models(X_train, y_train, X_val, y_val, models_to_train)\n",
    "    \n",
    "    # Step 7: Evaluate models\n",
    "    evaluation_results = evaluate_models(trained_models, X_test, y_test)\n",
    "    \n",
    "    # Step 8: Save best model\n",
    "    # Find best model based on F1 score\n",
    "    best_model_name = max(evaluation_results, key=lambda x: evaluation_results[x]['metrics']['f1'])\n",
    "    best_model = trained_models[best_model_name]['model']\n",
    "    \n",
    "    print(f\"\\nBest model: {trained_models[best_model_name]['name']}\")\n",
    "    print(f\"F1 Score: {evaluation_results[best_model_name]['metrics']['f1']:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    model_path = save_model(best_model, best_model_name, artifacts)\n",
    "    \n",
    "    # Create prediction pipeline\n",
    "    prediction_pipeline = create_prediction_pipeline(best_model, artifacts)\n",
    "    \n",
    "    print(\"\\nNetwork Intrusion Detection ML Pipeline completed successfully!\")\n",
    "    \n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_model_name': best_model_name,\n",
    "        'model_path': model_path,\n",
    "        'artifacts': artifacts,\n",
    "        'evaluation_results': evaluation_results,\n",
    "        'prediction_pipeline': prediction_pipeline\n",
    "    }\n",
    "\n",
    "# Execute main function if running as script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
